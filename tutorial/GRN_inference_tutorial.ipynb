{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Beeline benchmark to benchmark the performance of DeepSEM.\n",
    "The data preparation process are shown in below.\n",
    "1. Download raw data from https://doi.org/10.5281/zenodo.3378975, which is provided by BEELINE benchmark\n",
    "2. Use the preoprocess code in https://github.com/Murali-group/Beeline/blob/master/generateExpInputs.py to generate dataset.\n",
    "\n",
    "We also provide demo data as shown in ../demo_data/GRN_inference/input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run DeepSEM by using following command:\n",
    "for cell type specific GRN inference task: python main.py --task non_celltype_GRN --data_file demo_data/GRN_inference/input/500_STRING_hESC/data.csv --net_file demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new --alpha 100 --beta 1 --n_epoch 90 --save_name out\n",
    "\n",
    "\n",
    "for cell type non-specific GRN inference task: python main.py --task celltype_GRN --data_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/data.csv --net_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv --setting new --alpha 0.1 --beta 0.01 --n_epochs 150  --save_name out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python main.py --task non_celltype_GRN --data_file demo_data/GRN_inference/input/500_STRING_hESC/data.csv --net_file demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new --alpha 100 --beta 1 --n_epoch 90 --save_name out\n",
    "!python main.py --task celltype_GRN --data_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/data.csv --net_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv --setting new --alpha 0.1 --beta 0.01 --n_epochs 150  --save_name out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir exist\n",
      "epoch: 1 Ep: 107 Epr: 1.0450096454324784 loss: 3.3586705327033997 mse_loss: 0.9961295127868652 kl_loss: 2.3071235122624785 sparse_loss: 0.05541753148039182\n",
      "epoch: 2 Ep: 104 Epr: 1.0157103095792313 loss: 3.3077706694602966 mse_loss: 0.9957329382499059 kl_loss: 2.3087346121125543 sparse_loss: 0.0033031272857139506\n",
      "epoch: 4 Ep: 147 Epr: 1.435667456809106 loss: 3.2259697914123535 mse_loss: 0.8080269147952398 kl_loss: 2.4143110308796167 sparse_loss: 0.003631916013546288\n",
      "epoch: 5 Ep: 158 Epr: 1.5430983549376784 loss: 3.2243102391560874 mse_loss: 0.8066638261079788 kl_loss: 2.414142973100146 sparse_loss: 0.00350345221037666\n",
      "epoch: 7 Ep: 192 Epr: 1.8751574946078118 loss: 3.1519784132639566 mse_loss: 0.5288765281438828 kl_loss: 2.6165871769189835 sparse_loss: 0.006514674654075255\n",
      "epoch: 8 Ep: 205 Epr: 2.0021212833052155 loss: 3.149428923924764 mse_loss: 0.5274904171625773 kl_loss: 2.6120044166843095 sparse_loss: 0.009934067182863751\n",
      "epoch: 10 Ep: 211 Epr: 2.06071995501171 loss: 3.1452528635660806 mse_loss: 0.49311735729376477 kl_loss: 2.639834706981977 sparse_loss: 0.012300785475720962\n",
      "epoch: 11 Ep: 221 Epr: 2.1583844078558667 loss: 3.144018232822418 mse_loss: 0.4967267761627833 kl_loss: 2.6328772927323976 sparse_loss: 0.014414176810532808\n",
      "epoch: 13 Ep: 233 Epr: 2.275581751268855 loss: 3.142829477787018 mse_loss: 0.48709400246540707 kl_loss: 2.6395950143535933 sparse_loss: 0.016140448783213895\n",
      "epoch: 14 Ep: 228 Epr: 2.2267495248467766 loss: 3.141251862049103 mse_loss: 0.48662765324115753 kl_loss: 2.637128939231237 sparse_loss: 0.01749523961916566\n",
      "epoch: 16 Ep: 238 Epr: 2.3244139776909334 loss: 3.139966289202372 mse_loss: 0.47878481944402057 kl_loss: 2.6423964028557143 sparse_loss: 0.0187850723353525\n",
      "epoch: 17 Ep: 248 Epr: 2.42207843053509 loss: 3.138520618279775 mse_loss: 0.47958798458178836 kl_loss: 2.638833172619343 sparse_loss: 0.020099427395810682\n",
      "epoch: 19 Ep: 252 Epr: 2.461144211672753 loss: 3.137503206729889 mse_loss: 0.47939223796129227 kl_loss: 2.6369402607282004 sparse_loss: 0.021170681808143854\n",
      "epoch: 20 Ep: 259 Epr: 2.5295093286636625 loss: 3.137721002101898 mse_loss: 0.4800530771414439 kl_loss: 2.635809796551863 sparse_loss: 0.02185811009258032\n",
      "epoch: 22 Ep: 266 Epr: 2.5978744456545724 loss: 3.136493444442749 mse_loss: 0.46889136731624603 kl_loss: 2.644769827524821 sparse_loss: 0.022832288406789303\n",
      "epoch: 23 Ep: 267 Epr: 2.6076408909389883 loss: 3.1355844537417092 mse_loss: 0.47130391995112103 kl_loss: 2.640591333309809 sparse_loss: 0.023689212277531624\n",
      "epoch: 25 Ep: 265 Epr: 2.588108000370157 loss: 3.134984532992045 mse_loss: 0.4656153569618861 kl_loss: 2.644622745613257 sparse_loss: 0.024746397354950506\n",
      "epoch: 26 Ep: 266 Epr: 2.5978744456545724 loss: 3.1345353523890176 mse_loss: 0.4663875748713811 kl_loss: 2.6426402727762857 sparse_loss: 0.025507470437635977\n",
      "epoch: 28 Ep: 276 Epr: 2.695538898498729 loss: 3.1337404251098633 mse_loss: 0.4618810365597407 kl_loss: 2.6454998751481376 sparse_loss: 0.02635945628086726\n",
      "epoch: 29 Ep: 278 Epr: 2.7150717890675606 loss: 3.133779446283976 mse_loss: 0.4622822453578313 kl_loss: 2.6443532754977546 sparse_loss: 0.027143947469691437\n",
      "epoch: 31 Ep: 283 Epr: 2.763904015489639 loss: 3.132886071999868 mse_loss: 0.4599919219811757 kl_loss: 2.6452271242936454 sparse_loss: 0.02766705770045519\n",
      "epoch: 32 Ep: 285 Epr: 2.7834369060584705 loss: 3.132803718249003 mse_loss: 0.4590618635217349 kl_loss: 2.645390175282955 sparse_loss: 0.028351686739673216\n",
      "epoch: 34 Ep: 289 Epr: 2.8225026871961334 loss: 3.1319094697634378 mse_loss: 0.46575162808100384 kl_loss: 2.6374301264683404 sparse_loss: 0.028727728873491287\n",
      "epoch: 35 Ep: 290 Epr: 2.832269132480549 loss: 3.131959637006124 mse_loss: 0.4652155935764313 kl_loss: 2.63765095671018 sparse_loss: 0.029093066696077585\n",
      "epoch: 37 Ep: 292 Epr: 2.8518020230493804 loss: 3.131914039452871 mse_loss: 0.45513562113046646 kl_loss: 2.647215930124124 sparse_loss: 0.029562454981108505\n",
      "epoch: 38 Ep: 294 Epr: 2.871334913618212 loss: 3.1308037638664246 mse_loss: 0.4554508676131566 kl_loss: 2.6451544811328254 sparse_loss: 0.030198444612324238\n",
      "epoch: 40 Ep: 299 Epr: 2.92016714004029 loss: 3.129938840866089 mse_loss: 0.45890209327141446 kl_loss: 2.64031071215868 sparse_loss: 0.030726005633672077\n",
      "epoch: 41 Ep: 302 Epr: 2.949466475893537 loss: 3.130692640940348 mse_loss: 0.4597589721282323 kl_loss: 2.6398015841841698 sparse_loss: 0.031132118000338476\n",
      "epoch: 43 Ep: 301 Epr: 2.9397000306091217 loss: 3.130358656247457 mse_loss: 0.45280638585488003 kl_loss: 2.6459461425741515 sparse_loss: 0.03160616041471561\n",
      "epoch: 44 Ep: 308 Epr: 3.0080651476000315 loss: 3.1309774518013 mse_loss: 0.45235104362169903 kl_loss: 2.646503428618113 sparse_loss: 0.032122962176799774\n",
      "epoch: 46 Ep: 307 Epr: 2.9982987023156156 loss: 3.129568020502726 mse_loss: 0.4470077032844226 kl_loss: 2.6501384973526 sparse_loss: 0.03242181707173586\n",
      "epoch: 47 Ep: 313 Epr: 3.05689737402211 loss: 3.1287943522135415 mse_loss: 0.4475409264365832 kl_loss: 2.6482750500241914 sparse_loss: 0.03297833104928335\n",
      "epoch: 49 Ep: 316 Epr: 3.086196709875357 loss: 3.1286972165107727 mse_loss: 0.4497268721461296 kl_loss: 2.645725483695666 sparse_loss: 0.03324489357570807\n",
      "epoch: 50 Ep: 316 Epr: 3.086196709875357 loss: 3.1287864446640015 mse_loss: 0.44975680112838745 kl_loss: 2.6452242905894914 sparse_loss: 0.03380534642686447\n",
      "epoch: 52 Ep: 327 Epr: 3.193627608003929 loss: 3.1278759042421975 mse_loss: 0.4495190232992172 kl_loss: 2.644068012634913 sparse_loss: 0.0342888884867231\n",
      "epoch: 53 Ep: 328 Epr: 3.203394053288345 loss: 3.1281663179397583 mse_loss: 0.44977843513091403 kl_loss: 2.643581705788771 sparse_loss: 0.03480621427297592\n",
      "epoch: 55 Ep: 328 Epr: 3.203394053288345 loss: 3.1278340419133506 mse_loss: 0.4540766701102257 kl_loss: 2.6385769148667655 sparse_loss: 0.03518041626860698\n",
      "epoch: 56 Ep: 330 Epr: 3.2229269438571766 loss: 3.1275912324587503 mse_loss: 0.455563281973203 kl_loss: 2.636730750401815 sparse_loss: 0.035297222745915256\n",
      "epoch: 58 Ep: 328 Epr: 3.203394053288345 loss: 3.126611828804016 mse_loss: 0.45508625358343124 kl_loss: 2.636117825905482 sparse_loss: 0.03540770740558704\n",
      "epoch: 59 Ep: 328 Epr: 3.203394053288345 loss: 3.1275363167126975 mse_loss: 0.4547585720817248 kl_loss: 2.6372280046343803 sparse_loss: 0.035549758933484554\n",
      "epoch: 61 Ep: 331 Epr: 3.232693389141592 loss: 3.127639333407084 mse_loss: 0.4534976507226626 kl_loss: 2.6384125476082168 sparse_loss: 0.03572915059824785\n",
      "epoch: 62 Ep: 331 Epr: 3.232693389141592 loss: 3.1269182364145913 mse_loss: 0.4526258831222852 kl_loss: 2.6383153026302657 sparse_loss: 0.035977027068535485\n",
      "epoch: 64 Ep: 329 Epr: 3.2131604985727606 loss: 3.1264684200286865 mse_loss: 0.45139437913894653 kl_loss: 2.6389278868834176 sparse_loss: 0.03614618598173062\n",
      "epoch: 65 Ep: 330 Epr: 3.2229269438571766 loss: 3.1264788111050925 mse_loss: 0.45257368683815 kl_loss: 2.63755622257789 sparse_loss: 0.03634885139763355\n",
      "epoch: 67 Ep: 331 Epr: 3.232693389141592 loss: 3.126976410547892 mse_loss: 0.451199305554231 kl_loss: 2.6390721996625266 sparse_loss: 0.036704937306543194\n",
      "epoch: 68 Ep: 334 Epr: 3.261992724994839 loss: 3.1263744831085205 mse_loss: 0.45423688491185504 kl_loss: 2.63508519778649 sparse_loss: 0.03705243052293857\n",
      "epoch: 70 Ep: 336 Epr: 3.2815256155636705 loss: 3.12614240248998 mse_loss: 0.44053034484386444 kl_loss: 2.6482865139842033 sparse_loss: 0.037325537453095116\n",
      "epoch: 71 Ep: 337 Epr: 3.291292060848086 loss: 3.1253960132598877 mse_loss: 0.4391145780682564 kl_loss: 2.6486563657720885 sparse_loss: 0.03762504489471515\n",
      "epoch: 73 Ep: 341 Epr: 3.330357841985749 loss: 3.1253363688786826 mse_loss: 0.4450959637761116 kl_loss: 2.642246345678965 sparse_loss: 0.037994042659799256\n",
      "epoch: 74 Ep: 342 Epr: 3.3401242872701644 loss: 3.124586006005605 mse_loss: 0.4470159908135732 kl_loss: 2.6393878186742463 sparse_loss: 0.03818217540780703\n",
      "epoch: 76 Ep: 340 Epr: 3.3205913967013334 loss: 3.125982681910197 mse_loss: 0.44620219121376675 kl_loss: 2.641578033566475 sparse_loss: 0.03820244253923496\n",
      "epoch: 77 Ep: 340 Epr: 3.3205913967013334 loss: 3.1248880426088967 mse_loss: 0.4451604162653287 kl_loss: 2.6413431937495866 sparse_loss: 0.03838443569839001\n",
      "epoch: 79 Ep: 346 Epr: 3.3791900684078273 loss: 3.125165502230326 mse_loss: 0.43654564768075943 kl_loss: 2.649985765417417 sparse_loss: 0.038634128868579865\n",
      "epoch: 80 Ep: 350 Epr: 3.41825584954549 loss: 3.124724348386129 mse_loss: 0.4370373636484146 kl_loss: 2.64872944355011 sparse_loss: 0.03895750797043244\n",
      "epoch: 82 Ep: 351 Epr: 3.4280222948299057 loss: 3.1246204376220703 mse_loss: 0.4389339089393616 kl_loss: 2.646505976716677 sparse_loss: 0.03918056314190229\n",
      "epoch: 83 Ep: 354 Epr: 3.4573216306831527 loss: 3.124237378438314 mse_loss: 0.4386737644672394 kl_loss: 2.6460825949907303 sparse_loss: 0.03948104133208593\n",
      "epoch: 85 Ep: 356 Epr: 3.476854521251984 loss: 3.124423702557882 mse_loss: 0.4447367613514264 kl_loss: 2.6402164176106453 sparse_loss: 0.0394705186287562\n",
      "epoch: 86 Ep: 359 Epr: 3.506153857105231 loss: 3.1247700254122415 mse_loss: 0.4456007753809293 kl_loss: 2.6396347731351852 sparse_loss: 0.03953452408313751\n",
      "epoch: 88 Ep: 358 Epr: 3.4963874118208156 loss: 3.1238442262013755 mse_loss: 0.43629201253255206 kl_loss: 2.6477414394418397 sparse_loss: 0.03981075653185447\n",
      "epoch: 89 Ep: 355 Epr: 3.4670880759675686 loss: 3.1238200068473816 mse_loss: 0.43560249855120975 kl_loss: 2.6482947344581285 sparse_loss: 0.03992279587934414\n"
     ]
    }
   ],
   "source": [
    "! python D:/Bachelor/MinorGraduationProject/CSIPSystem/CSIP/DeepSEM/main.py --task non_celltype_GRN --data_file D:/Bachelor/MinorGraduationProject/CSIPSystem/CSIP/DeepSEM/demo_data/GRN_inference/input/500_STRING_hESC/data.csv --net_file D:/Bachelor/MinorGraduationProject/CSIPSystem/CSIP/DeepSEM/demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new --alpha 100 --beta 1 --n_epoch 90 --save_name out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate EPR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.12143991002342"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "output = pd.read_csv('../demo_data/GRN_inference/output/500_STRING_hESC_demo_output.tsv',sep='\\t')\n",
    "output['EdgeWeight'] = abs(output['EdgeWeight'])\n",
    "output = output.sort_values('EdgeWeight',ascending=False)\n",
    "label = pd.read_csv('../demo_data/GRN_inference/input//500_STRING_hESC/label.csv')\n",
    "TFs = set(label['Gene1'])\n",
    "Genes = set(label['Gene1'])| set(label['Gene2'])\n",
    "output = output[output['Gene1'].apply(lambda x: x in TFs)]\n",
    "output = output[output['Gene2'].apply(lambda x: x in Genes)]\n",
    "label_set = set(label['Gene1']+'|'+label['Gene2'])\n",
    "output= output.iloc[:len(label_set)]\n",
    "len(set(output['Gene1']+'|' +output['Gene2']) & label_set) / (len(label_set)**2/(len(TFs)*len(Genes)-len(TFs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate AUPR ratio values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.052970499172538"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "output = pd.read_csv('../demo_data/GRN_inference/output/500_STRING_hESC_demo_output.tsv',sep='\\t')\n",
    "output['EdgeWeight'] = abs(output['EdgeWeight'])\n",
    "output = output.sort_values('EdgeWeight',ascending=False)\n",
    "label = pd.read_csv('../demo_data/GRN_inference/input//500_STRING_hESC/label.csv')\n",
    "TFs = set(label['Gene1'])\n",
    "Genes = set(label['Gene1'])| set(label['Gene2'])\n",
    "output = output[output['Gene1'].apply(lambda x: x in TFs)]\n",
    "output = output[output['Gene2'].apply(lambda x: x in Genes)]\n",
    "label_set = set(label['Gene1']+label['Gene2'])\n",
    "preds,labels,randoms = [] ,[],[]\n",
    "res_d = {}\n",
    "l = []\n",
    "p= []\n",
    "for item in (output.to_dict('records')):\n",
    "        res_d[item['Gene1']+item['Gene2']] = item['EdgeWeight']\n",
    "for item in (set(label['Gene1'])):\n",
    "        for item2 in  set(label['Gene1'])| set(label['Gene2']):\n",
    "            if item+item2 in label_set:\n",
    "                l.append(1)\n",
    "            else:\n",
    "                l.append(0)\n",
    "            if item+ item2 in res_d:\n",
    "                p.append(res_d[item+item2])\n",
    "            else:\n",
    "                p.append(-1)\n",
    "average_precision_score(l,p)/np.mean(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble DeepSEM result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(10):\n",
    "    res.append(pd.read_csv('../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv',sep='\\t'))\n",
    "res = pd.concat(res)\n",
    "res['EdgeWeight'] = abs(res['EdgeWeight'])\n",
    "res.groupby(['Gene1','Gene2']).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
